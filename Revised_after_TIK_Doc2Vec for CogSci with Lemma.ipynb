{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb\n",
    "\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lee_train_file=\"C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Train_18000_plus_random.txt\"\n",
    "lee_test_file=\"C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/04082020_CengizHocaTalebi/Test_cogsci_conf_2000_02_04_09_10_11_12_13_14_15_16_17_18_19_plus_Other_Conferences.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization process\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "iteration_count = [0]\n",
    "from gensim.utils import lemmatize\n",
    "#from pattern.en import lemma\n",
    "\n",
    "def lemmat(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        print (iteration_count[0])\n",
    "        for i, line in enumerate(f):\n",
    "            #tokens = gensim.utils.lemmatize(line,allowed_tags=re.compile('(NN|VB|JJ|RB)'), light=False, stopwords=frozenset({}), min_length=2, max_length=15)\n",
    "            tokens=[wd.decode('utf-8').split('/')[0] for wd in lemmatize(line)]\n",
    "            #tokens=[wd.decode('utf-8').split('/')[0] for wd in lemma(line)]\n",
    "            iteration_count[0]+=1\n",
    "            print (iteration_count[0])\n",
    "            if tokens_only:\n",
    "                #yield str(tokens)\n",
    "                yield list(tokens)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield TaggedDocument(tokens, [i])\n",
    "                #yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "test_corpus = list(lemmat(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check how test corpus look like after lemmatization. It creates a txt file\n",
    "    \n",
    "with open('C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/confs_test_corpus_list_to_text.txt', 'w') as f:\n",
    "    for item in test_corpus:\n",
    "        #f.write(\"{0}\\n\".format(item))\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "train_demo_corpus = list(lemmat(lee_train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check how train corpus look like after lemmatization. It creates a txt file\n",
    "    \n",
    "with open('C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/18KRnd_train_corpus_list_to_text.txt', 'w') as f:\n",
    "    for item in train_demo_corpus:\n",
    "        f.write(\"{0}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this part for just to change the test file for lemmat option\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "lee_test_file=\"C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/04082020_CengizHocaTalebi/Test_cogsci_conf_2000_02_04_09_10_11_12_13_14_15_16_17_18_19_plus_Other_Conferences.txt\"\n",
    "test_corpus = list(lemmat(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If not preprocessing required, use this part:\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        \n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "                \n",
    "train_demo_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the types\n",
    "print(type(test_corpus[0]))\n",
    "print(type(test_corpus[:]))\n",
    "print(type(train_demo_corpus[0]))\n",
    "print(type(train_demo_corpus[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_corpus[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_demo_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-16 10:36:24,426 : INFO : using concatenative 7500-dimensional layer1\n",
      "2021-05-16 10:37:17,552 : INFO : collecting all words and their counts\n",
      "2021-05-16 10:37:17,630 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2021-05-16 10:41:40,831 : INFO : collected 129858 word types and 7 unique tags from a corpus of 7 examples and 12960501 words\n",
      "2021-05-16 10:41:40,898 : INFO : Loading a fresh vocabulary\n",
      "2021-05-16 10:41:42,310 : INFO : effective_min_count=5 retains 46377 unique words (35% of original 129858, drops 83481)\n",
      "2021-05-16 10:41:42,310 : INFO : effective_min_count=5 leaves 12819868 word corpus (98% of original 12960501, drops 140633)\n",
      "2021-05-16 10:41:42,672 : INFO : deleting the raw counts dictionary of 129858 items\n",
      "2021-05-16 10:41:42,688 : INFO : sample=0.001 downsamples 15 most-common words\n",
      "2021-05-16 10:41:42,688 : INFO : downsampling leaves estimated 12165723 word corpus (94.9% of prior 12819868)\n",
      "2021-05-16 10:41:43,016 : INFO : constructing a huffman tree from 46378 words\n",
      "2021-05-16 10:41:49,682 : INFO : built huffman tree with maximum node depth 22\n",
      "2021-05-16 10:41:49,697 : INFO : estimated required memory for 46377 words and 300 dimensions: 1479434700 bytes\n",
      "2021-05-16 10:41:49,728 : INFO : resetting layer weights\n",
      "2021-05-16 10:41:51,771 : INFO : training model with 3 workers on 46378 vocabulary and 7500 features, using sg=0 hs=1 sample=0.001 negative=0 window=12\n",
      "2021-05-16 10:41:53,012 : INFO : EPOCH 1 - PROGRESS: at 14.29% examples, 8083 words/s, in_qsize 6, out_qsize 0\n",
      "2021-05-16 10:41:54,126 : INFO : EPOCH 1 - PROGRESS: at 57.14% examples, 16952 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:41:54,126 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:41:54,160 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:41:55,032 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:41:55,033 : INFO : EPOCH - 1 : training on 12960501 raw words (70007 effective words) took 3.3s, 21502 effective words/s\n",
      "2021-05-16 10:41:56,501 : INFO : EPOCH 2 - PROGRESS: at 14.29% examples, 9660 words/s, in_qsize 5, out_qsize 0\n",
      "2021-05-16 10:41:57,603 : INFO : EPOCH 2 - PROGRESS: at 57.14% examples, 18707 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:41:57,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:41:58,011 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:41:58,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:41:58,530 : INFO : EPOCH - 2 : training on 12960501 raw words (70007 effective words) took 3.1s, 22862 effective words/s\n",
      "2021-05-16 10:41:59,676 : INFO : EPOCH 3 - PROGRESS: at 14.29% examples, 8896 words/s, in_qsize 5, out_qsize 0\n",
      "2021-05-16 10:42:00,777 : INFO : EPOCH 3 - PROGRESS: at 57.14% examples, 17945 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:42:00,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:42:00,881 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:42:01,673 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:42:01,673 : INFO : EPOCH - 3 : training on 12960501 raw words (70007 effective words) took 3.1s, 22408 effective words/s\n",
      "2021-05-16 10:42:02,836 : INFO : EPOCH 4 - PROGRESS: at 14.29% examples, 8781 words/s, in_qsize 5, out_qsize 0\n",
      "2021-05-16 10:42:03,889 : INFO : EPOCH 4 - PROGRESS: at 57.14% examples, 18156 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:42:03,958 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:42:03,979 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:42:04,802 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:42:04,802 : INFO : EPOCH - 4 : training on 12960501 raw words (70007 effective words) took 3.1s, 22543 effective words/s\n",
      "2021-05-16 10:42:05,932 : INFO : EPOCH 5 - PROGRESS: at 14.29% examples, 8869 words/s, in_qsize 6, out_qsize 0\n",
      "2021-05-16 10:42:06,984 : INFO : EPOCH 5 - PROGRESS: at 57.14% examples, 18325 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:42:06,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:42:06,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:42:07,862 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:42:07,894 : INFO : EPOCH - 5 : training on 12960501 raw words (70007 effective words) took 3.1s, 22653 effective words/s\n",
      "2021-05-16 10:42:09,013 : INFO : EPOCH 6 - PROGRESS: at 14.29% examples, 8966 words/s, in_qsize 5, out_qsize 0\n",
      "2021-05-16 10:42:10,066 : INFO : EPOCH 6 - PROGRESS: at 57.14% examples, 18423 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:42:10,082 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:42:10,082 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:42:10,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:42:10,943 : INFO : EPOCH - 6 : training on 12960501 raw words (70007 effective words) took 3.0s, 22963 effective words/s\n",
      "2021-05-16 10:42:12,075 : INFO : EPOCH 7 - PROGRESS: at 14.29% examples, 9262 words/s, in_qsize 6, out_qsize 0\n",
      "2021-05-16 10:42:13,128 : INFO : EPOCH 7 - PROGRESS: at 57.14% examples, 18678 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:42:13,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:42:13,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:42:14,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:42:14,025 : INFO : EPOCH - 7 : training on 12960501 raw words (70007 effective words) took 3.0s, 23025 effective words/s\n",
      "2021-05-16 10:42:15,140 : INFO : EPOCH 8 - PROGRESS: at 14.29% examples, 9001 words/s, in_qsize 5, out_qsize 0\n",
      "2021-05-16 10:42:16,225 : INFO : EPOCH 8 - PROGRESS: at 57.14% examples, 18276 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:42:16,284 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:42:16,299 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:42:17,106 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:42:17,106 : INFO : EPOCH - 8 : training on 12960501 raw words (70007 effective words) took 3.1s, 22819 effective words/s\n",
      "2021-05-16 10:42:18,175 : INFO : EPOCH 9 - PROGRESS: at 14.29% examples, 9315 words/s, in_qsize 6, out_qsize 0\n",
      "2021-05-16 10:42:19,243 : INFO : EPOCH 9 - PROGRESS: at 57.14% examples, 18652 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:42:19,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:42:19,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:42:20,135 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:42:20,136 : INFO : EPOCH - 9 : training on 12960501 raw words (70007 effective words) took 3.0s, 23154 effective words/s\n",
      "2021-05-16 10:42:21,287 : INFO : EPOCH 10 - PROGRESS: at 14.29% examples, 8633 words/s, in_qsize 6, out_qsize 0\n",
      "2021-05-16 10:42:22,308 : INFO : EPOCH 10 - PROGRESS: at 57.14% examples, 18420 words/s, in_qsize 3, out_qsize 0\n",
      "2021-05-16 10:42:22,444 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-05-16 10:42:22,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-16 10:42:23,202 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-16 10:42:23,218 : INFO : EPOCH - 10 : training on 12960501 raw words (70007 effective words) took 3.1s, 22754 effective words/s\n",
      "2021-05-16 10:42:23,218 : INFO : training on a 129605010 raw words (700070 effective words) took 31.4s, 22264 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "#covers the following three steps in one block\n",
    "#You can change the parameters and re-run this block to see the results for different parameters.\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = gensim.models.doc2vec.Doc2Vec(dm=1, vector_size=300, window=12, min_count=5, epochs=10, hs=1, negative=0, dm_mean=0, dm_concat=1, dbow_words=0)\n",
    "model.build_vocab(train_demo_corpus)\n",
    "%time model.train(train_demo_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#Instantiate a Doc2Vec Object\n",
    "#model = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=2, epochs=40)\n",
    "\n",
    "#mymodel_1: for model.save\n",
    "#model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40, dm=1, window=12, dm_concat=1, dbow_words=1)\n",
    "\n",
    "#mymodel_2: for model.save\n",
    "#model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40, dm=1, window=8)\n",
    "\n",
    "#mymodel_3: for model.save\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=500, min_count=2, epochs=40, dm=1, window=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a Vocabulary\n",
    "model.build_vocab(train_demo_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to Train\n",
    "%time model.train(train_demo_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-16 13:20:17,211 : INFO : saving Doc2Vec object under C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/mymodel_15_lemma_train_18KRnd_test_confs.doc2vec, separately None\n",
      "2021-05-16 13:20:18,647 : INFO : storing np array 'syn1' to C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/mymodel_15_lemma_train_18KRnd_test_confs.doc2vec.trainables.syn1.npy\n",
      "2021-05-16 13:31:23,564 : INFO : storing np array 'vectors' to C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/mymodel_15_lemma_train_18KRnd_test_confs.doc2vec.wv.vectors.npy\n",
      "2021-05-16 13:35:58,770 : INFO : saved C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/mymodel_15_lemma_train_18KRnd_test_confs.doc2vec\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model.save(\"C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/mymodel_15_lemma_train_18KRnd_test_confs.doc2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "model = Doc2Vec.load(\"C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/mymodel_2_train_12600_test_5400.doc2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferring a Vector\n",
    "model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assessing Model\n",
    "\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_demo_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_demo_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's count how each document ranks with respect to the training corpus\n",
    "collections.Counter(ranks)  # Results vary between runs due to random seeding and very small corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Testing the Model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d = []\n",
    "\n",
    "for doc_id in range(32400):\n",
    "    reg_list_real=[]\n",
    "    reg_list_ideal=[]\n",
    "    \n",
    "    inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    #print (sims)\n",
    "    a, b = zip(*sims)\n",
    "    \n",
    "    \n",
    "    reg_list_real=list(b)\n",
    "    \n",
    "    max= 0\n",
    "    for i in reg_list_real:\n",
    "        if i > max:\n",
    "            max=i\n",
    "      \n",
    "    reg_list_ideal=[0] * 5\n",
    "    \n",
    "    reg_list_ideal.insert(0,100)\n",
    "    \n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    slope, intercept, r_value, p_value, std_err=stats.linregress(reg_list_real,reg_list_ideal)\n",
    "    #print(\"p_value: %f\" % (p_value))\n",
    "    \n",
    "    \n",
    "    d.append({a[0]:(b[0]),a[1]:(b[1]),a[2]:(b[2]),a[3]:(b[3]),a[4]:(b[4]),a[5]:(b[5]),\"P Value\":p_value})\n",
    "\n",
    "    \n",
    "     \n",
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(d).style.apply(highlight_max,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-16 10:59:02,665 : INFO : precomputing L2-norms of doc weight vectors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow0_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow1_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow2_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow3_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow4_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow5_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow6_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow7_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow8_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow9_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow10_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow11_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow12_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow13_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow14_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow15_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow16_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow17_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow18_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow19_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow20_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow21_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_247811fe_b61d_11eb_9ac5_9283ed8e751arow22_col5 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751a\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >0</th> \n",
       "        <th class=\"col_heading level0 col1\" >1</th> \n",
       "        <th class=\"col_heading level0 col2\" >2</th> \n",
       "        <th class=\"col_heading level0 col3\" >3</th> \n",
       "        <th class=\"col_heading level0 col4\" >4</th> \n",
       "        <th class=\"col_heading level0 col5\" >5</th> \n",
       "        <th class=\"col_heading level0 col6\" >6</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow0_col0\" class=\"data row0 col0\" >0.373172</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow0_col1\" class=\"data row0 col1\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow0_col2\" class=\"data row0 col2\" >0.295814</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow0_col3\" class=\"data row0 col3\" >0.00778591</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow0_col4\" class=\"data row0 col4\" >0.264358</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow0_col5\" class=\"data row0 col5\" >0.464784</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow0_col6\" class=\"data row0 col6\" >0.123766</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow1_col0\" class=\"data row1 col0\" >0.271933</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow1_col1\" class=\"data row1 col1\" >0.0601192</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow1_col2\" class=\"data row1 col2\" >0.321407</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow1_col3\" class=\"data row1 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow1_col4\" class=\"data row1 col4\" >0.433317</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow1_col5\" class=\"data row1 col5\" >0.265531</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow1_col6\" class=\"data row1 col6\" >0.0481458</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow2_col0\" class=\"data row2 col0\" >0.360544</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow2_col1\" class=\"data row2 col1\" >-0.00358302</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow2_col2\" class=\"data row2 col2\" >0.298545</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow2_col3\" class=\"data row2 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow2_col4\" class=\"data row2 col4\" >0.110258</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow2_col5\" class=\"data row2 col5\" >0.370504</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow2_col6\" class=\"data row2 col6\" >0.00978443</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow3_col0\" class=\"data row3 col0\" >0.152672</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow3_col1\" class=\"data row3 col1\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow3_col2\" class=\"data row3 col2\" >0.744304</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow3_col3\" class=\"data row3 col3\" >0.0585248</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow3_col4\" class=\"data row3 col4\" >0.323835</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow3_col5\" class=\"data row3 col5\" >0.244433</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow3_col6\" class=\"data row3 col6\" >0.177952</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row4\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow4_col0\" class=\"data row4 col0\" >0.167759</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow4_col1\" class=\"data row4 col1\" >0.062426</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow4_col2\" class=\"data row4 col2\" >0.0863857</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow4_col3\" class=\"data row4 col3\" >0.153543</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow4_col4\" class=\"data row4 col4\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow4_col5\" class=\"data row4 col5\" >0.219314</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow4_col6\" class=\"data row4 col6\" >0.0698339</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row5\" class=\"row_heading level0 row5\" >5</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow5_col0\" class=\"data row5 col0\" >0.251018</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow5_col1\" class=\"data row5 col1\" >0.0877785</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow5_col2\" class=\"data row5 col2\" >0.260999</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow5_col3\" class=\"data row5 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow5_col4\" class=\"data row5 col4\" >0.252427</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow5_col5\" class=\"data row5 col5\" >0.212305</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow5_col6\" class=\"data row5 col6\" >0.0140103</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row6\" class=\"row_heading level0 row6\" >6</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow6_col0\" class=\"data row6 col0\" >0.287231</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow6_col1\" class=\"data row6 col1\" >0.0247264</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow6_col2\" class=\"data row6 col2\" >0.184695</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow6_col3\" class=\"data row6 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow6_col4\" class=\"data row6 col4\" >0.239292</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow6_col5\" class=\"data row6 col5\" >0.22293</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow6_col6\" class=\"data row6 col6\" >0.0532599</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row7\" class=\"row_heading level0 row7\" >7</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow7_col0\" class=\"data row7 col0\" >0.297983</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow7_col1\" class=\"data row7 col1\" >0.0547377</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow7_col2\" class=\"data row7 col2\" >0.284185</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow7_col3\" class=\"data row7 col3\" >-0.018377</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow7_col4\" class=\"data row7 col4\" >0.360812</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow7_col5\" class=\"data row7 col5\" >0.184703</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow7_col6\" class=\"data row7 col6\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row8\" class=\"row_heading level0 row8\" >8</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow8_col0\" class=\"data row8 col0\" >0.295035</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow8_col1\" class=\"data row8 col1\" >0.0509408</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow8_col2\" class=\"data row8 col2\" >0.254389</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow8_col3\" class=\"data row8 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow8_col4\" class=\"data row8 col4\" >0.147488</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow8_col5\" class=\"data row8 col5\" >0.214976</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow8_col6\" class=\"data row8 col6\" >0.0649323</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row9\" class=\"row_heading level0 row9\" >9</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow9_col0\" class=\"data row9 col0\" >0.247896</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow9_col1\" class=\"data row9 col1\" >0.0925752</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow9_col2\" class=\"data row9 col2\" >0.275277</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow9_col3\" class=\"data row9 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow9_col4\" class=\"data row9 col4\" >0.207969</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow9_col5\" class=\"data row9 col5\" >0.307416</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow9_col6\" class=\"data row9 col6\" >0.0448428</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row10\" class=\"row_heading level0 row10\" >10</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow10_col0\" class=\"data row10 col0\" >0.331376</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow10_col1\" class=\"data row10 col1\" >0.178711</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow10_col2\" class=\"data row10 col2\" >0.472002</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow10_col3\" class=\"data row10 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow10_col4\" class=\"data row10 col4\" >0.0567144</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow10_col5\" class=\"data row10 col5\" >0.226604</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow10_col6\" class=\"data row10 col6\" >-0.023166</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row11\" class=\"row_heading level0 row11\" >11</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow11_col0\" class=\"data row11 col0\" >0.279554</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow11_col1\" class=\"data row11 col1\" >0.175533</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow11_col2\" class=\"data row11 col2\" >0.179114</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow11_col3\" class=\"data row11 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow11_col4\" class=\"data row11 col4\" >0.189335</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow11_col5\" class=\"data row11 col5\" >0.194293</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow11_col6\" class=\"data row11 col6\" >-0.0152338</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row12\" class=\"row_heading level0 row12\" >12</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow12_col0\" class=\"data row12 col0\" >0.250094</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow12_col1\" class=\"data row12 col1\" >-0.0297108</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow12_col2\" class=\"data row12 col2\" >0.32956</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow12_col3\" class=\"data row12 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow12_col4\" class=\"data row12 col4\" >0.22428</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow12_col5\" class=\"data row12 col5\" >0.342767</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow12_col6\" class=\"data row12 col6\" >0.0630347</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row13\" class=\"row_heading level0 row13\" >13</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow13_col0\" class=\"data row13 col0\" >0.218025</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow13_col1\" class=\"data row13 col1\" >0.0652915</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow13_col2\" class=\"data row13 col2\" >0.173621</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow13_col3\" class=\"data row13 col3\" >0.052028</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow13_col4\" class=\"data row13 col4\" >0.270873</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow13_col5\" class=\"data row13 col5\" >0.32463</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow13_col6\" class=\"data row13 col6\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row14\" class=\"row_heading level0 row14\" >14</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow14_col0\" class=\"data row14 col0\" >0.2463</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow14_col1\" class=\"data row14 col1\" >0.324</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow14_col2\" class=\"data row14 col2\" >0.02038</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow14_col3\" class=\"data row14 col3\" >0.0623736</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow14_col4\" class=\"data row14 col4\" >0.209116</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow14_col5\" class=\"data row14 col5\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow14_col6\" class=\"data row14 col6\" >0.143004</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row15\" class=\"row_heading level0 row15\" >15</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow15_col0\" class=\"data row15 col0\" >0.555567</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow15_col1\" class=\"data row15 col1\" >0.383204</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow15_col2\" class=\"data row15 col2\" >0.254355</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow15_col3\" class=\"data row15 col3\" >-0.0414176</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow15_col4\" class=\"data row15 col4\" >0.0467996</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow15_col5\" class=\"data row15 col5\" >0.216633</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow15_col6\" class=\"data row15 col6\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row16\" class=\"row_heading level0 row16\" >16</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow16_col0\" class=\"data row16 col0\" >0.834882</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow16_col1\" class=\"data row16 col1\" >0.389481</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow16_col2\" class=\"data row16 col2\" >0.107823</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow16_col3\" class=\"data row16 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow16_col4\" class=\"data row16 col4\" >0.0513982</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow16_col5\" class=\"data row16 col5\" >0.0754882</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow16_col6\" class=\"data row16 col6\" >-0.00214433</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row17\" class=\"row_heading level0 row17\" >17</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow17_col0\" class=\"data row17 col0\" >0.722615</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow17_col1\" class=\"data row17 col1\" >0.182545</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow17_col2\" class=\"data row17 col2\" >0.104976</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow17_col3\" class=\"data row17 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow17_col4\" class=\"data row17 col4\" >0.0845693</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow17_col5\" class=\"data row17 col5\" >0.156972</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow17_col6\" class=\"data row17 col6\" >0.1021</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row18\" class=\"row_heading level0 row18\" >18</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow18_col0\" class=\"data row18 col0\" >-0.084015</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow18_col1\" class=\"data row18 col1\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow18_col2\" class=\"data row18 col2\" >0.0835076</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow18_col3\" class=\"data row18 col3\" >0.0395894</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow18_col4\" class=\"data row18 col4\" >0.762999</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow18_col5\" class=\"data row18 col5\" >0.147351</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow18_col6\" class=\"data row18 col6\" >0.377791</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row19\" class=\"row_heading level0 row19\" >19</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow19_col0\" class=\"data row19 col0\" >0.0605456</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow19_col1\" class=\"data row19 col1\" >0.0354761</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow19_col2\" class=\"data row19 col2\" >0.0159415</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow19_col3\" class=\"data row19 col3\" >0.0228901</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow19_col4\" class=\"data row19 col4\" >0.616835</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow19_col5\" class=\"data row19 col5\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow19_col6\" class=\"data row19 col6\" >0.307319</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row20\" class=\"row_heading level0 row20\" >20</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow20_col0\" class=\"data row20 col0\" >0.136333</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow20_col1\" class=\"data row20 col1\" >0.139453</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow20_col2\" class=\"data row20 col2\" >-0.0144898</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow20_col3\" class=\"data row20 col3\" >0.341426</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow20_col4\" class=\"data row20 col4\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow20_col5\" class=\"data row20 col5\" >0.252543</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow20_col6\" class=\"data row20 col6\" >-0.00402518</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row21\" class=\"row_heading level0 row21\" >21</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow21_col0\" class=\"data row21 col0\" >0.283911</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow21_col1\" class=\"data row21 col1\" >0.250055</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow21_col2\" class=\"data row21 col2\" >0.0899503</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow21_col3\" class=\"data row21 col3\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow21_col4\" class=\"data row21 col4\" >-0.0633842</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow21_col5\" class=\"data row21 col5\" >0.667175</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow21_col6\" class=\"data row21 col6\" >-0.0751518</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751alevel0_row22\" class=\"row_heading level0 row22\" >22</th> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow22_col0\" class=\"data row22 col0\" >0.0774595</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow22_col1\" class=\"data row22 col1\" >0.0574548</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow22_col2\" class=\"data row22 col2\" >nan</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow22_col3\" class=\"data row22 col3\" >0.0689838</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow22_col4\" class=\"data row22 col4\" >0.020373</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow22_col5\" class=\"data row22 col5\" >0.713836</td> \n",
       "        <td id=\"T_247811fe_b61d_11eb_9ac5_9283ed8e751arow22_col6\" class=\"data row22 col6\" >-0.0523361</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xa4d1db38>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the Model without P values\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d = []\n",
    "\n",
    "for doc_id in range(23):\n",
    "    reg_list_real=[]\n",
    "    reg_list_ideal=[]\n",
    "    \n",
    "    inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    #print (sims)\n",
    "    a, b = zip(*sims)\n",
    "    \n",
    "    \n",
    "    d.append({a[0]:(b[0]),a[1]:(b[1]),a[2]:(b[2]),a[3]:(b[3]),a[4]:(b[4]),a[5]:(b[5])})\n",
    "    #d.append({a[0]:(b[0]),a[1]:(b[1]),a[2]:(b[2]),a[3]:(b[3]),a[4]:(b[4]),a[5]:(b[5]),a[6]:(b[6])})\n",
    "    #d.append({a[0]:(b[0])})\n",
    "    #d.append({a[0]:(b[0]),a[1]:(b[1]),a[2]:(b[2]),a[3]:(b[3]),a[4]:(b[4]),a[5]:(b[5]),a[6]:(b[6]),a[7]:(b[7]),a[8]:(b[8]),a[9]:(b[9]),a[10]:(b[10]),a[11]:(b[11]),a[12]:(b[12]),a[13]:(b[13]),a[14]:(b[14]),a[15]:(b[15]),a[16]:(b[16]),a[17]:(b[17]),a[18]:(b[18]),a[19]:(b[19]),a[20]:(b[20]),a[21]:(b[21]),a[22]:(b[22]),a[23]:(b[23]),a[24]:(b[24]),a[25]:(b[25]),a[26]:(b[26]),a[27]:(b[27]),a[28]:(b[28]),a[29]:(b[29]),a[30]:(b[30]),a[31]:(b[31]),a[32]:(b[32]),a[33]:(b[33]),a[34]:(b[34]),a[35]:(b[35]),a[36]:(b[36]),a[37]:(b[37]),a[38]:(b[38]),a[39]:(b[39]),a[40]:(b[40]),a[41]:(b[41]),a[42]:(b[42]),a[43]:(b[43]),a[44]:(b[44]),a[45]:(b[45]),a[46]:(b[46]),a[47]:(b[47]),a[48]:(b[48]),a[49]:(b[49])})\n",
    "     \n",
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(d).style.apply(highlight_max,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export above table as csv file\n",
    "\n",
    "pd.DataFrame(d).style.apply(highlight_max,axis=1).to_excel(\"C:/Users/ENF_RP/Desktop/Journals/Doc2Vec/CogSCI/Revised_Study_After_TIK/New_Study_for_Conference_31_12_2019/Hyperparamater_Optimization/mymodel_15_lemma_train_18KRnd_test_confs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (0): «introductio human possess remarkably rich adaptive conceptual knowledge system enable»\n",
      "\n",
      "Test Document (1): «tutorial introduce participant cpm gom modele used apex tool applied»\n",
      "\n",
      "Test Document (2): «qualitative modeling cognitive science gautam biswa biswa vuse vanderbilt edu»\n",
      "\n",
      "Test Document (3): «argument quality perspective participant hahn hahnu cf ac uk school»\n",
      "\n",
      "Test Document (4): «overcome computational ecological divide self sustain system wild system theory»\n",
      "\n",
      "Test Document (5): «tutorial model comparison method jay myung myung osu edu department»\n",
      "\n",
      "Test Document (6): «woman cognitive science sponsor interactive panel discussion professional advancement leadership»\n",
      "\n",
      "Test Document (7): «keyword diagram visuospatial representation external representation problem solve diagrammatic reasoning»\n",
      "\n",
      "Test Document (8): «online experiment used jspsych psiturk amazon mechanical turk joshua edu»\n",
      "\n",
      "Test Document (9): «half day workshop provide information hand experience relate apply national»\n",
      "\n",
      "Test Document (10): «active learn cognitive development education computational model organizer elizabeth bonawitz»\n",
      "\n",
      "Test Document (11): «tutorial recent advance deep learn matthew botvinick botvinick google com»\n",
      "\n",
      "Test Document (12): «neil stewart warwick business school behavioral science discuss machine record»\n",
      "\n",
      "Test Document (13): «heuristic hack habit boundedly optimal approach learn reasoning decision make»\n",
      "\n",
      "Test Document (14): «introduction progress be be make eu country planned implementation gd»\n",
      "\n",
      "Test Document (15): «distinctiveness horror film music film sound theorist donnelly begin inquiry»\n",
      "\n",
      "Test Document (16): «thing make sense louise antony university massachusett amherst presidential address»\n",
      "\n",
      "Test Document (17): «passion reason hume kant motivation morality paul guyer brown university»\n",
      "\n",
      "Test Document (18): «benchmark dataset evaluation methodology video object segmentation perazzi pont tuset»\n",
      "\n",
      "Test Document (19): «big datum meet big water analytic ais ship tracking datum»\n",
      "\n",
      "Test Document (20): «award distinguished scientific contribution terrie moffitt avshalom caspi apa award»\n",
      "\n",
      "Test Document (21): «dear participant be delighted welcome international psychological application conference trend»\n",
      "\n",
      "Test Document (22): «structural model parenting style attachment style self regulation self esteem»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To be sure about the doc number and text matching\n",
    "for f in range(23):\n",
    "    print('Test Document ({}): «{}»\\n'.format(f, ' '.join(test_corpus[f][:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
